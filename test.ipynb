{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "rows = df.shape[0]\n",
    "print(rows)\n",
    "df.head(5)\n",
    "\n",
    "# We'll regress petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 120\n",
      "test size: 30\n",
      "[[5.1 3.5 1.4]]\n",
      "[[6.9 3.2 5.7]]\n"
     ]
    }
   ],
   "source": [
    "trainSize = int(0.8 * rows)\n",
    "\n",
    "# to_numpy and squeeze for micrograd compatibility\n",
    "\n",
    "trainX = df.iloc[:trainSize,:-1].to_numpy()\n",
    "trainY = df.iloc[:trainSize,-1:].to_numpy().squeeze(1)\n",
    "\n",
    "testX = df.iloc[trainSize:,:-1].to_numpy()\n",
    "testY = df.iloc[trainSize:,-1:].to_numpy().squeeze(1)\n",
    "\n",
    "print(f'train size: {len(trainX)}')\n",
    "print(f'test size: {len(testY)}')\n",
    "\n",
    "print(trainX[:1])\n",
    "print(testX[:1])\n",
    "# trainY.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll compare the MSE between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09499934208144371"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression(copy_X=True).fit(trainX, trainY)\n",
    "lrPreds = linreg.predict(testX)\n",
    "mse = mean_squared_error(testY, lrPreds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nn\n",
    "from micrograd import Value\n",
    "from utils import train_mlp_mse, predict\n",
    "from visualizers import visualizeMlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"214pt\" height=\"152pt\"\n",
       " viewBox=\"0.00 0.00 214.49 152.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 148)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-148 210.49,-148 210.49,4 -4,4\"/>\n",
       "<!-- 140132491017568 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140132491017568</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"168.79\" cy=\"-72\" rx=\"37.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.79\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">out_0,0</text>\n",
       "</g>\n",
       "<!-- 0140132495820832 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>0140132495820832</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30.55\" cy=\"-126\" rx=\"30.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"30.55\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">inp_0</text>\n",
       "</g>\n",
       "<!-- 0140132495820832&#45;&gt;140132491017568 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0140132495820832&#45;&gt;140132491017568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.22,-116.22C76.71,-108.1 106.2,-96.41 129.71,-87.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.05,-90.33 139.05,-83.39 128.47,-83.82 131.05,-90.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"96.09\" y=\"-109.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_0,0</text>\n",
       "</g>\n",
       "<!-- 1140132495820832 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1140132495820832</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30.55\" cy=\"-72\" rx=\"30.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"30.55\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">inp_1</text>\n",
       "</g>\n",
       "<!-- 1140132495820832&#45;&gt;140132491017568 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1140132495820832&#45;&gt;140132491017568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M61.11,-72C78.57,-72 101.07,-72 120.9,-72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.99,-75.5 130.99,-72 120.99,-68.5 120.99,-75.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"96.09\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_0,1</text>\n",
       "</g>\n",
       "<!-- 2140132495820832 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2140132495820832</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30.55\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"30.55\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">inp_2</text>\n",
       "</g>\n",
       "<!-- 2140132495820832&#45;&gt;140132491017568 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2140132495820832&#45;&gt;140132491017568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.22,-27.78C76.71,-35.9 106.2,-47.59 129.71,-56.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.47,-60.18 139.05,-60.61 131.05,-53.67 128.47,-60.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"96.09\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\">w_0,2</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f73275b5210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnLR = nn.LinearRegressor(len(trainX[0]), activation=Value.Identity)\n",
    "visualizeMlp(nnLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10779453231098389]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 0.0001 # learning rate needs to be really small. Loss was exploding with 0.001 and above\n",
    "loss = train_mlp_mse(nnLR, trainX, trainY, epochs=epochs, lr=lr, verbose=False)\n",
    "nnPreds = predict(nnLR, testX)\n",
    "loss[-1:]\n",
    "\n",
    "# loss gets stuck at around 59.49\n",
    "# I think I am running into the vanishing gradients problem, and\n",
    "# the model stops learning at one point. Implementing more activations\n",
    "\n",
    "# OHHH actually, there should be no activation! this is linear regression!\n",
    "\n",
    "# Not able to do much better than around 2.8 loss with 1000 epochs and 0.0001 learning rate\n",
    "# and we approach this min loss around 100-500 epochs (varies). I think we need much better \n",
    "# initialization for network to do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.97506335, 1.74310351, 2.25376822, 1.5950917 , 2.03038313])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.predict(testX[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Value(data=1.9815020557065404)],\n",
       " [Value(data=1.521346630962297)],\n",
       " [Value(data=2.7787886509260433)],\n",
       " [Value(data=1.839270787286899)],\n",
       " [Value(data=1.8487866778122701)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(nnLR, testX[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.16953887439780266)\n",
      "0.16953887439780266\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(testY, nnPreds))\n",
    "print(sum(pred[0].squaredDist(gold) for pred, gold in zip(nnPreds, testY)).data / len(testY))\n",
    "\n",
    "# Why are these values different?\n",
    "# loss was *not* normalizing over number of examples (not dividing by len(testY))\n",
    "# it's just a constant so it doesn't matter for gradient descent, but necessary\n",
    "# for interpreting loss as the mse of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.3704175568606625),\n",
       " Value(data=-0.5863186652213832),\n",
       " Value(data=0.2664250836424197),\n",
       " Value(data=-0.21678233468539676)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnLR.parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
